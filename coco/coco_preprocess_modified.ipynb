{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCO data preprocessing\n",
    "\n",
    "This code will download the caption anotations for coco and preprocess them into an hdf5 file and a json file. \n",
    "\n",
    "These will then be read by the COCO data loader in Lua and trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets download the annotations from http://mscoco.org/dataset/#download\n",
    "import os\n",
    "os.system('wget http://msvocds.blob.core.windows.net/annotations-1-0-3/captions_train-val2014.zip') # ~19MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('unzip captions_train-val2014.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "val = json.load(open('Data/final_data_val.json', 'r'))\n",
    "infoOfVal = json.load(open('Data/final_data_val.json', 'r'))\n",
    "infoOfVal = infoOfVal['images']\n",
    "val['images'] = infoOfVal\n",
    "#train = json.load(open('annotations/captions_train2014.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['images', 'annotations'])\n39792\n39792\n{'caption': ['गंदगी सड़क पर एक छोटा सा मोपेड पर लाल हेलमेट वाले एक आदमी', 'मनुष्य ग्रामीण इलाकों में एक गंदगी सड़क पर मोटर बाइक चला रहा है।', 'एक मोटरसाइकिल के पीछे की सवारी वाली एक आदमी', 'मोटर बाइक पर एक युवा व्यक्ति के साथ एक गंदगी पथ एक सब्जी क्षेत्र के पुल के साथ एक पुल और बादल-पुष्कृत पहाड़ों की पृष्ठभूमि के साथ स्थित है।', 'एक लाल शर्ट में एक आदमी और एक लाल टोपी एक पहाड़ी की ओर एक मोटरसाइकिल पर है।'], 'image_id': 391895}\n"
     ]
    }
   ],
   "source": [
    "print( val.keys() )\n",
    "#print( val['info'] )\n",
    "print( len(val['images']) )\n",
    "print( len(val['annotations']) )\n",
    "#print( val['images'][0] )\n",
    "print( val['annotations'][0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# combine all images and annotations together\n",
    "imgs = val['images']#+ train['images']\n",
    "annots = val['annotations']# + train['annotations']\n",
    "\n",
    "# for efficiency lets group annotations by image\n",
    "itoa = {}\n",
    "for a in annots:\n",
    "    imgid = a['image_id']\n",
    "    if not imgid in itoa: itoa[imgid] = []\n",
    "    itoa[imgid].append(a)\n",
    "\n",
    "# create the json blob\n",
    "out = []\n",
    "for i,img in enumerate(imgs):\n",
    "    imgid = img['id']\n",
    "    \n",
    "    # coco specific here, they store train/val images separately\n",
    "    loc = 'train2014' if 'train' in img['file_name'] else 'val2014'\n",
    "    \n",
    "    jimg = {}\n",
    "    jimg['file_path'] = os.path.join(loc, img['file_name'])\n",
    "    jimg['id'] = imgid\n",
    "    \n",
    "    sents = []\n",
    "    annotsi = itoa[imgid]\n",
    "    for a in annotsi:\n",
    "        sents.append(a['caption'])\n",
    "    jimg['captions'] = sents\n",
    "    out.append(jimg)\n",
    "    \n",
    "json.dump(out, open('/home/himanshu/DL/caption/hindi-captioning/Data/coco_raw.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_path': 'val2014/COCO_val2014_000000391895.jpg', 'id': 391895, 'captions': [['गंदगी सड़क पर एक छोटा सा मोपेड पर लाल हेलमेट वाले एक आदमी', 'मनुष्य ग्रामीण इलाकों में एक गंदगी सड़क पर मोटर बाइक चला रहा है।', 'एक मोटरसाइकिल के पीछे की सवारी वाली एक आदमी', 'मोटर बाइक पर एक युवा व्यक्ति के साथ एक गंदगी पथ एक सब्जी क्षेत्र के पुल के साथ एक पुल और बादल-पुष्कृत पहाड़ों की पृष्ठभूमि के साथ स्थित है।', 'एक लाल शर्ट में एक आदमी और एक लाल टोपी एक पहाड़ी की ओर एक मोटरसाइकिल पर है।']]}\n"
     ]
    }
   ],
   "source": [
    "# lets see what they look like\n",
    "print(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
